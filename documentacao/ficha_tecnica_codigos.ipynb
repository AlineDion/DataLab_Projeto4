{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8759802",
   "metadata": {},
   "source": [
    "# Ficha Técnica - Códigos\n",
    "\n",
    "#### DataLAB para Amazon Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d66b493",
   "metadata": {},
   "source": [
    "### Conectar/importar dados para outras ferramentas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237402b2",
   "metadata": {},
   "source": [
    "#### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610a57a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar as bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2a0395",
   "metadata": {},
   "source": [
    "#### Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57434246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar os datasets\n",
    "product_df = pd.read_csv ('/content/amazon_product.csv')\n",
    "review_df = pd.read_csv ('/content/amazon_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64393de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo as primeiras 2 linhas do dataset\n",
    "display(review_df.head(2))\n",
    "display(product_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaa8993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar número de linhas e colunas de cada tabela\n",
    "print(\"Número de linhas e colunas na tabela product:\")\n",
    "display(product_df.shape)\n",
    "\n",
    "print(\"\\nNúmero de linhas e colunas na tabela review:\")\n",
    "display(review_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad12e54",
   "metadata": {},
   "source": [
    "#### Identificar e Tratar Valores Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar valores nulos\n",
    "print(\"Valores nulos na tabela product:\")\n",
    "display(product_df.isnull().sum())\n",
    "\n",
    "print(\"\\nValores nulos na tabela review:\")\n",
    "display(review_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650ee2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover linhas com valores nulos na coluna 'about_product' do dataframe product\n",
    "product_df.dropna(subset=['about_product'], inplace=True)\n",
    "\n",
    "# Remover linhas com valores nulos na coluna 'rating_count' do dataframe review\n",
    "review_df.dropna(subset=['rating_count'], inplace=True)\n",
    "\n",
    "print(\"Valores nulos na tabela product após a remoção:\")\n",
    "display(product_df.isnull().sum())\n",
    "\n",
    "print(\"\\nValores nulos na tabela review após a remoção:\")\n",
    "display(review_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6067ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trazer as primeiras 5 linhas do dataframe\n",
    "print(\"Primeiras 5 linhas da tabela product após o tratamento de valores nulos:\")\n",
    "display(product_df.head())\n",
    "\n",
    "print(\"\\nPrimeiras 5 linhas da tabela review após o tratamento de valores nulos:\")\n",
    "display(review_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1b6ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar número de linhas após a exclusão dos nulos\n",
    "print(\"Número de linhas na tabela product após a exclusão de nulos:\")\n",
    "display(product_df.shape[0])\n",
    "\n",
    "print(\"\\nNúmero de linhas na tabela review após a exclusão de nulos:\")\n",
    "display(review_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef83237a",
   "metadata": {},
   "source": [
    "##### Identificar e Tratar Valores Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fc9c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover linhas duplicadas com base na coluna 'product_id' do dataframe product\n",
    "product_df.drop_duplicates(subset=['product_id'], inplace=True)\n",
    "\n",
    "# Remover linhas duplicadas com base na coluna 'product_id, user_id, review_id' do dataframe review\n",
    "review_df.drop_duplicates(subset=['product_id', 'user_id', 'review_id'], inplace=True)\n",
    "\n",
    "print(\"Número de linhas na tabela product após a remoção de duplicados:\")\n",
    "display(product_df.shape[0])\n",
    "\n",
    "print(\"\\nNúmero de linhas na tabela review após a remoção de duplicados:\")\n",
    "display(review_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f4909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trazer o número de duplicadas excluidas em cada coluna\n",
    "product_original = pd.read_csv ('/content/drive/MyDrive/amazon_dataset.zip (Unzipped Files)/amazon - amazon_product.csv')\n",
    "review_original = pd.read_csv ('/content/drive/MyDrive/amazon_dataset.zip (Unzipped Files)/amazon - amazon_review.csv')\n",
    "\n",
    "# Calcular numero de duplicados removidos\n",
    "product_duplicates_removed = product_original.shape[0] - product_df.shape[0]\n",
    "review_duplicates_removed = review_original.shape[0] - review_df.shape[0]\n",
    "\n",
    "print(f\"Número de duplicatas removidas na tabela product: {product_duplicates_removed}\")\n",
    "print(f\"Número de duplicatas removidas na tabela review: {review_duplicates_removed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0817354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar duplicatas no DataFrame 'product' com base em 'product_id' (dupla checagem)\n",
    "duplicatas_product_id = product_df.duplicated(subset=['product_id']).sum()\n",
    "print(f\"Número de duplicatas na coluna 'product_id' do DataFrame 'product': {duplicatas_product_id}\")\n",
    "\n",
    "# Verificar duplicatas no DataFrame 'review' com base em 'user_id', 'review_id', 'product_id'\n",
    "duplicatas_review_subset = review_df.duplicated(subset=['user_id', 'review_id', 'product_id']).sum()\n",
    "print(f\"Número de duplicatas nas colunas ['user_id', 'review_id', 'product_id'] do DataFrame 'review': {duplicatas_review_subset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ecb19",
   "metadata": {},
   "source": [
    "#### Identificar e Tratar Dados Fora do Escopo de Análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fd4196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir estatísticas descritivas de todas as colunas de review_df e em product_df\n",
    "print(\"\\nInformações estatísticas de review_df:\")\n",
    "display(review_df.describe(include='all'))\n",
    "print(\"\\nInformações estatísticas de product_df:\")\n",
    "display(product_df.describe(include='all'))\n",
    "\n",
    "# Converter a coluna 'rating' para tipo numérico, tratando erros como NaN (caso haja valores inválidos)\n",
    "review_df['rating'] = pd.to_numeric(review_df['rating'], errors='coerce')\n",
    "\n",
    "# Definir os limites válidos de avaliação (rating)\n",
    "min_rating = 1\n",
    "max_rating = 5\n",
    "\n",
    "# Filtrar linhas com valores de avaliação fora do escopo definido\n",
    "out_of_scope_reviews = review_df[(review_df['rating'] < min_rating) | (review_df['rating'] > max_rating)]\n",
    "\n",
    "# Exibir as avaliações fora do escopo (1 a 5)\n",
    "print(f\"\\nAvaliações fora do escopo ({min_rating}-{max_rating}) em review_df:\")\n",
    "display(out_of_scope_reviews)\n",
    "\n",
    "# Listar os valores únicos das colunas categóricas em review_df e product_df (até 10 primeiros), para verificar inconsistências\n",
    "print(\"\\nValores únicos em colunas categóricas de review_df:\")\n",
    "categorical_cols_review = review_df.select_dtypes(include=['object', 'category']).columns\n",
    "for col in categorical_cols_review:\n",
    "    print(f\"{col}: {review_df[col].unique()[:1]}...\") \n",
    "\n",
    "print(\"\\nValores únicos em colunas categóricas de product_df:\")\n",
    "categorical_cols_product = product_df.select_dtypes(include=['object', 'category']).columns\n",
    "for col in categorical_cols_product:\n",
    "    print(f\"{col}: {product_df[col].unique()[:1]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5673393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluir as colunas 'img_link' e 'product_link' do DataFrame review \n",
    "review_df.drop(['img_link', 'product_link'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20883f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se todas as correções até o momento foram feitas corretamente\n",
    "print(\"DataFrame 'product' após exclusão de lihas nulas em 'about_product':\")\n",
    "display(product_df.head())\n",
    "print(\"\\nContagem de nulos em 'about_product' no DataFrame 'product':\")\n",
    "print(product_df['about_product'].isnull().sum())\n",
    "\n",
    "\n",
    "print(\"\\nDataFrame 'review' após exclusão de linhas nulas em 'rating_count' e colunas 'img_link' e 'product_link':\")\n",
    "display(review_df.head())\n",
    "print(\"\\nContagem de nulos em 'rating_count' no DataFrame 'review':\")\n",
    "print(review_df['rating_count'].isnull().sum())\n",
    "print(\"\\nColunas restantes no DataFrame 'review':\")\n",
    "print(review_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101f756e",
   "metadata": {},
   "source": [
    "#### Identificar e Tratar Dados Discrepantes em Variáveis Categóricas, Numéricas e Verificação do Tipo de Dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368191f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detectar e exibir valores inconsistentes, erros de digitação, categorias inesperadas ou dados fora do escopo\n",
    "print(\"Valores únicos em colunas categóricas de review_df:\")\n",
    "categorical_cols_review = review_df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "for col in categorical_cols_review:\n",
    "    uniques = review_df[col].dropna().unique()\n",
    "    standardized_uniques = pd.Series(uniques).astype(str).str.strip().str.lower().unique()\n",
    "\n",
    "    discrepancias_potenciais = len(uniques) - len(standardized_uniques)\n",
    "    exemplo_valores = uniques[:1] # Mostrar o primeiro 1 valor encontrado\n",
    "\n",
    "    print(f\"\\nColuna: {col}\")\n",
    "    print(f\"Valores únicos (limitado a 1): {exemplo_valores}\")\n",
    "    print(f\"Total de valores únicos: {len(uniques)}\")\n",
    "    print(f\"Possíveis discrepâncias de caixa/espaco: {discrepancias_potenciais}\")\n",
    "\n",
    "print(\"\\nValores únicos em colunas categóricas de product_df:\")\n",
    "categorical_cols_product = product_df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "for col in categorical_cols_product:\n",
    "    uniques = product_df[col].dropna().unique()\n",
    "    standardized_uniques = pd.Series(uniques).astype(str).str.strip().str.lower().unique()\n",
    "\n",
    "    discrepancias_potenciais = len(uniques) - len(standardized_uniques)\n",
    "    exemplo_valores = uniques[:1] # Mostrar o primeiro 1 valor encontrado\n",
    "\n",
    "    print(f\"\\nColuna: {col}\")\n",
    "    print(f\"Valores únicos (limitado a 1): {exemplo_valores}\")\n",
    "    print(f\"Total de valores únicos: {len(uniques)}\")\n",
    "    print(f\"Possíveis discrepâncias de caixa/espaco: {discrepancias_potenciais}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2d41da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de limpeza de colunas numéricas com símbolos\n",
    "def limpa_coluna_numerica(serie, moeda=False, percentual=False):\n",
    "    serie = serie.astype(str).str.strip()\n",
    "\n",
    "    if moeda:\n",
    "        serie = serie.str.replace('₹', '', regex=False)\n",
    "\n",
    "    if percentual:\n",
    "        serie = serie.str.replace('%', '', regex=False)\n",
    "\n",
    "    serie = serie.str.replace(',', '', regex=False)\n",
    "\n",
    "    # Substitui 'nan' string por string vazia\n",
    "    serie = serie.replace('nan', '')\n",
    "\n",
    "    # Converte para numérico (float), erros viram NaN\n",
    "    serie = pd.to_numeric(serie, errors='coerce')\n",
    "\n",
    "    return serie\n",
    "\n",
    "# Agora aplicamos em cada dataframe\n",
    "\n",
    "# Para product\n",
    "product_df['discounted_price'] = limpa_coluna_numerica(product_df['discounted_price'], moeda=True)\n",
    "product_df['actual_price'] = limpa_coluna_numerica(product_df['actual_price'], moeda=True)\n",
    "product_df['discount_percentage'] = limpa_coluna_numerica(product_df['discount_percentage'], percentual=True)\n",
    "# Para review:\n",
    "review_df['rating_count'] = limpa_coluna_numerica(review_df['rating_count'])\n",
    "review_df['rating'] = pd.to_numeric(review_df['rating'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722fab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar alterações nas colunas exibindos as 5 primeiras linhas \n",
    "print(\"Primeiras 5 linhas da tabela product_df após a conversão:\")\n",
    "display(product_df.head())\n",
    "\n",
    "print(\"\\nPrimeiras 5 linhas da tabela review_df após a conversão:\")\n",
    "display(review_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e68e007",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data types in product_df:\")\n",
    "display(product_df.dtypes)\n",
    "\n",
    "print(\"\\nData types in review_df:\")\n",
    "display(review_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403a608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para identificar outliers usando IQR\n",
    "def find_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    return outliers\n",
    "\n",
    "print(\"Outliers identificados em review_df (usando IQR):\")\n",
    "for col in review_df.select_dtypes(include=['number']).columns:\n",
    "    outliers = find_outliers_iqr(review_df, col)\n",
    "    print(f\"\\nColuna: {col} - Total de outliers: {len(outliers)}\")\n",
    "    if not outliers.empty:\n",
    "        display(outliers)\n",
    "    else:\n",
    "        print(f\"Coluna: {col} - Nenhum outlier encontrado.\")\n",
    "\n",
    "\n",
    "print(\"\\nOutliers identificados em product_df (usando IQR):\")\n",
    "for col in product_df.select_dtypes(include=['number']).columns:\n",
    "    outliers = find_outliers_iqr(product_df, col)\n",
    "    print(f\"\\nColuna: {col} - Total de outliers: {len(outliers)}\")\n",
    "    if not outliers.empty:\n",
    "        display(outliers)\n",
    "    else:\n",
    "        print(f\"Coluna: {col} - Nenhum outlier encontrado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ac86bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "\n",
    "# Função para identificar outliers usando Z-Score\n",
    "def find_outliers_zscore(df, column, threshold=3):\n",
    "    z_scores = np.abs(zscore(df[column]))\n",
    "    outliers = df[z_scores > threshold]\n",
    "    return outliers\n",
    "\n",
    "print(\"Outliers identificados em review_df (usando Z-Score com threshold=3):\")\n",
    "for col in review_df.select_dtypes(include=['number']).columns:\n",
    "    outliers = find_outliers_zscore(review_df, col)\n",
    "    print(f\"\\nColuna: {col} - Total de outliers: {len(outliers)}\")\n",
    "    if not outliers.empty:\n",
    "        display(outliers)\n",
    "    else:\n",
    "        print(f\"Coluna: {col} - Nenhum outlier encontrado.\")\n",
    "\n",
    "\n",
    "print(\"\\nOutliers identificados em product_df (usando Z-Score com threshold=3):\")\n",
    "for col in product_df.select_dtypes(include=['number']).columns:\n",
    "    outliers = find_outliers_zscore(product_df, col)\n",
    "    print(f\"\\nColuna: {col} - Total de outliers: {len(outliers)}\")\n",
    "    if not outliers.empty:\n",
    "        display(outliers)\n",
    "    else:\n",
    "        print(f\"Coluna: {col} - Nenhum outlier encontrado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc635b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualização para colunas numéricas em review_df\n",
    "print(\"Visualização da distribuição para colunas numéricas em review_df:\")\n",
    "for col in review_df.select_dtypes(include=['number']).columns:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1) # 1 linha, 2 colunas, 1º gráfico\n",
    "    sns.boxplot(x=review_df[col])\n",
    "    plt.title(f'Box plot de {col}')\n",
    "\n",
    "    plt.subplot(1, 2, 2) # 1 linha, 2 colunas, 2º gráfico\n",
    "    sns.histplot(review_df[col], kde=True)\n",
    "    plt.title(f'Histograma de {col}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualização para colunas numéricas em product_df\n",
    "print(\"\\nVisualização da distribuição para colunas numéricas em product_df:\")\n",
    "for col in product_df.select_dtypes(include=['number']).columns:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1) # 1 linha, 2 colunas, 1º gráfico\n",
    "    sns.boxplot(x=product_df[col])\n",
    "    plt.title(f'Box plot de {col}')\n",
    "\n",
    "    plt.subplot(1, 2, 2) # 1 linha, 2 colunas, 2º gráfico\n",
    "    sns.histplot(product_df[col], kde=True)\n",
    "    plt.title(f'Histograma de {col}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6df6f3",
   "metadata": {},
   "source": [
    "#### Criar novas Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a77a57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar a coluna 'diferenca_preco'\n",
    "# Certifique-se de que 'actual_price' e 'discounted_price' são numéricos\n",
    "product_df['diferenca_preco'] = product_df['actual_price'] - product_df['discounted_price']\n",
    "\n",
    "# Criar a coluna 'categoria_principal'\n",
    "# Extrair a primeira categoria antes do primeiro '|'\n",
    "product_df['categoria_principal'] = product_df['category'].astype(str).str.split('|', expand=True)[0]\n",
    "\n",
    "print(\"Primeiras 5 linhas do dataframe product_df com as novas colunas:\")\n",
    "display(product_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd7b472",
   "metadata": {},
   "source": [
    "#### Unir Tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319d944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir os dataframes product_df e review_df usando a coluna 'product_id'\n",
    "# Usamos um 'inner' join para incluir apenas produtos que têm avaliações e vice-versa\n",
    "unificada_df = pd.merge(product_df, review_df, on='product_id', how='inner')\n",
    "\n",
    "print(\"Primeiras 5 linhas do dataframe unido:\")\n",
    "display(unificada_df.head())\n",
    "\n",
    "print(\"\\nNúmero de linhas e colunas no dataframe unido:\")\n",
    "display(unificada_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5863b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contagem de valores nulos após união das tabelas\n",
    "print(\"Contagem de valores nulos no dataframe unido:\")\n",
    "display(unificada_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fa799d",
   "metadata": {},
   "source": [
    "#### Agrupar e Visualizar Dados de Acordo com Variáveis Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973f74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por 'categoria_principal' e calcular a média das colunas numéricas\n",
    "\n",
    "# Convert 'discount_percentage' to numeric after removing '%'\n",
    "unificada_df['discount_percentage'] = unificada_df['discount_percentage'].astype(str).str.replace('%', '').astype(float)\n",
    "\n",
    "# Convert 'rating_count' to numeric after removing ','\n",
    "unificada_df['rating_count'] = unificada_df['rating_count'].astype(str).str.replace(',', '').astype(float)\n",
    "\n",
    "\n",
    "categoria_principal_grouped = unificada_df.groupby('categoria_principal').agg(\n",
    "    mean_discounted_price=('discounted_price', 'mean'),\n",
    "    mean_actual_price=('actual_price', 'mean'),\n",
    "    mean_discount_percentage=('discount_percentage', 'mean'),\n",
    "    mean_diferenca_preco=('diferenca_preco', 'mean'),\n",
    "    mean_rating=('rating', 'mean'),\n",
    "    mean_rating_count=('rating_count', 'mean'),\n",
    "    product_count=('product_id', 'count')\n",
    ").reset_index()\n",
    "\n",
    "print(\"Agregação por categoria_principal:\")\n",
    "display(categoria_principal_grouped)\n",
    "\n",
    "# Calcular o percentual de produtos em cada categoria em relação ao total de produtos\n",
    "total_products = unificada_df.shape[0]\n",
    "categoria_principal_grouped['percentage_of_products'] = (categoria_principal_grouped['product_count'] / total_products) * 100\n",
    "\n",
    "print(\"\\nAgregação por categoria_principal com porcentagem de produtos:\")\n",
    "display(categoria_principal_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b5b185",
   "metadata": {},
   "source": [
    "#### Ver variáveis ​​categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28da8f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar a frequência de cada categoria principal\n",
    "categoria_principal_counts = unificada_df['categoria_principal'].value_counts()\n",
    "\n",
    "# Criar um gráfico de barras\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=categoria_principal_counts.index, y=categoria_principal_counts.values)\n",
    "plt.title('Distribuição de Produtos por Categoria Principal')\n",
    "plt.xlabel('Categoria Principal')\n",
    "plt.ylabel('Número de Produtos')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c5a383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the proportion of each main category\n",
    "proporcao_categorias = unificada_df['categoria_principal'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Proporção de cada Categoria Principal:\")\n",
    "print(proporcao_categorias)\n",
    "\n",
    "# Select the top 4 categories\n",
    "top_4_categorias = proporcao_categorias.head(4)\n",
    "\n",
    "# Create a bar chart for the top 4 categories\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=top_4_categorias.index, y=top_4_categorias.values, palette='viridis')\n",
    "plt.title('Proporção das Top 4 Categorias Principais')\n",
    "plt.xlabel('Categoria Principal')\n",
    "plt.ylabel('Proporção (%)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60d7eae",
   "metadata": {},
   "source": [
    "#### Medidas de Tendência Central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c1bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar colunas numéricas\n",
    "numerical_cols = unificada_df.select_dtypes(include=np.number).columns\n",
    "\n",
    "print(\"Estatísticas de Tendência Central para Variáveis Numéricas:\")\n",
    "\n",
    "# Calcular Média, Mediana e Moda para cada coluna numérica\n",
    "for col in numerical_cols:\n",
    "    mean_val = unificada_df[col].mean()\n",
    "    median_val = unificada_df[col].median()\n",
    "    mode_val = unificada_df[col].mode()\n",
    "\n",
    "    print(f\"\\n--- Coluna: {col} ---\")\n",
    "    print(f\"Média: {mean_val:.2f}\")\n",
    "    print(f\"Mediana: {median_val:.2f}\")\n",
    "    # Mode can have multiple values, so handle accordingly\n",
    "    print(f\"Moda: {list(mode_val.round(2))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e80d539",
   "metadata": {},
   "source": [
    "#### Aplicar Medidas de Dispersão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e330e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Medidas de Dispersão para Variáveis Numéricas:\")\n",
    "\n",
    "# Calcular Desvio Padrão, Variância e Intervalo Interquartílico para cada coluna numérica\n",
    "for col in numerical_cols:\n",
    "    std_dev = unificada_df[col].std()\n",
    "    variance = unificada_df[col].var()\n",
    "    Q1 = unificada_df[col].quantile(0.25)\n",
    "    Q3 = unificada_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    print(f\"\\n--- Coluna: {col} ---\")\n",
    "    print(f\"Desvio Padrão: {std_dev:.2f}\")\n",
    "    print(f\"Variância: {variance:.2f}\")\n",
    "    print(f\"Intervalo Interquartílico (IQR): {IQR:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed4ac99",
   "metadata": {},
   "source": [
    "#### Correlação entre Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5114820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a matriz de correlação de Pearson para as variáveis numéricas\n",
    "correlation_matrix = unificada_df[numerical_cols].corr(method='pearson')\n",
    "\n",
    "print(\"Matriz de Correlação de Pearson entre as variáveis numéricas:\")\n",
    "display(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeaf033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar segmentos com base na categoria principal\n",
    "segmented_by_categoria_principal = unificada_df.groupby('categoria_principal')\n",
    "\n",
    "# Exibir o resumo estatístico para cada segmento (categoria principal)\n",
    "print(\"Resumo Estatístico por Categoria Principal:\")\n",
    "display(segmented_by_categoria_principal.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e32a18",
   "metadata": {},
   "source": [
    "#### Validação de Hipóteses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe51d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hipótese 1: Quanto maior o desconto, melhor será a pontuação.\n",
    "print(\"\\n--- Análise da Hipótese 1: Desconto vs. Pontuação ---\")\n",
    "\n",
    "# Correlação de Spearman (mais robusta a outliers e relações não lineares)\n",
    "spearman_corr_h1, spearman_p_value_h1 = stats.spearmanr(unificada_df['discount_percentage'], unificada_df['rating'])\n",
    "print(f\"Correlação de Spearman entre Desconto e Rating: {spearman_corr_h1:.4f}, P-valor: {spearman_p_value_h1:.4f}\")\n",
    "\n",
    "# Visualização (Scatter plot com linha de regressão)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='discount_percentage', y='rating', data=unificada_df, scatter_kws={'alpha':0.3})\n",
    "plt.title('Relação entre Percentual de Desconto e Pontuação (Rating)')\n",
    "plt.xlabel('Percentual de Desconto (%)')\n",
    "plt.ylabel('Pontuação Média')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7668e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hipótese 2: Quanto maior o número de pessoas que avaliaram o produto, melhor será a classificação.\n",
    "print(\"\\n--- Análise da Hipótese 2: Número de Avaliações vs. Classificação ---\")\n",
    "\n",
    "# Correlação de Pearson\n",
    "pearson_corr_h2, pearson_p_value_h2 = stats.pearsonr(unificada_df['rating_count'], unificada_df['rating'])\n",
    "print(f\"Correlação de Pearson entre Rating Count e Rating: {pearson_corr_h2:.4f}, P-valor: {pearson_p_value_h2:.4f}\")\n",
    "\n",
    "# Correlação de Spearman\n",
    "spearman_corr_h2, spearman_p_value_h2 = stats.spearmanr(unificada_df['rating_count'], unificada_df['rating'])\n",
    "print(f\"Correlação de Spearman entre Rating Count e Rating: {spearman_corr_h2:.4f}, P-valor: {spearman_p_value_h2:.4f}\")\n",
    "\n",
    "# Visualização para a Hipótese 2: Número de Avaliações vs. Classificação\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='rating_count', y='rating', data=unificada_df, scatter_kws={'alpha':0.3}) # scatter_kws para ajustar a transparência dos pontos\n",
    "plt.title('Relação entre Número de Avaliações e Pontuação (Rating)')\n",
    "plt.xlabel('Número de Avaliações')\n",
    "plt.ylabel('Pontuação Média')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf3fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hipótese 3: Produtos com preços reais mais altos (sem desconto aplicado) tendem a ter uma avaliação maior.\n",
    "print(\"\\n--- Análise da Hipótese 3: Preço Real vs. Avaliação ---\")\n",
    "\n",
    "# Correlação de Pearson\n",
    "# fillna(0) apenas para o cálculo da correlação se houver NaN\n",
    "pearson_corr_h3, pearson_p_value_h3 = stats.pearsonr(unificada_df['actual_price'].fillna(0), unificada_df['rating'])\n",
    "print(f\"Correlação de Pearson entre Preço Real e Rating: {pearson_corr_h3:.4f}, P-valor: {pearson_p_value_h3:.4f}\")\n",
    "\n",
    "# Correlação de Spearman\n",
    "spearman_corr_h3, spearman_p_value_h3 = stats.spearmanr(unificada_df['actual_price'].fillna(0), unificada_df['rating'])\n",
    "print(f\"Correlação de Spearman entre Preço Real e Rating: {spearman_corr_h3:.4f}, P-valor: {spearman_p_value_h3:.4f}\")\n",
    "\n",
    "# Visualização para a Hipótese 3: Preço Real vs. Avaliação\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='actual_price', y='rating', data=unificada_df, scatter_kws={'alpha':0.3}) # scatter_kws para ajustar a transparência dos pontos\n",
    "plt.title('Relação entre Preço Real e Pontuação (Rating)')\n",
    "plt.xlabel('Preço Real')\n",
    "plt.ylabel('Pontuação Média')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a663ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hipótese 4: Produtos com um preço real mais alto tendem a ter descontos absolutos maiores (ou seja, o valor do desconto em R$)\n",
    "print(\"\\n--- Análise da Hipótese 4: Preço Real vs. Diferença de Preço ---\")\n",
    "\n",
    "# Correlação de Pearson\n",
    "pearson_corr_h4, pearson_p_value_h4 = stats.pearsonr(unificada_df['actual_price'].fillna(0), unificada_df['diferenca_preco'].fillna(0))\n",
    "print(f\"Correlação de Pearson entre Preço Real e Diferença de Preço: {pearson_corr_h4:.4f}, P-valor: {pearson_p_value_h4:.4f}\")\n",
    "\n",
    "# Correlação de Spearman\n",
    "spearman_corr_h4, spearman_p_value_h4 = stats.spearmanr(unificada_df['actual_price'].fillna(0), unificada_df['diferenca_preco'].fillna(0))\n",
    "print(f\"Correlação de Spearman entre Preço Real e Diferença de Preço: {spearman_corr_h4:.4f}, P-valor: {spearman_p_value_h4:.4f}\")\n",
    "\n",
    "# Visualização para a Hipótese 4: Preço Real vs. Diferença de Preço\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='actual_price', y='diferenca_preco', data=unificada_df, scatter_kws={'alpha':0.3}) # scatter_kws para ajustar a transparência dos pontos\n",
    "plt.title('Relação entre Preço Real e Diferença de Preço')\n",
    "plt.xlabel('Preço Real')\n",
    "plt.ylabel('Diferença de Preço (Valor do Desconto)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b316ca",
   "metadata": {},
   "source": [
    "#### Confirmação da Hipótese 4 com Testes Complementares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6b95ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar o teste ANOVA para Comparar a Média da Diferença de Preço entre Categorias\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Teste ANOVA\n",
    "model = ols('diferenca_preco ~ C(categoria_principal)', data=unificada_df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "print(\"Tabela ANOVA:\")\n",
    "display(anova_table)\n",
    "\n",
    "# Interpretar o resultado do ANOVA\n",
    "alpha = 0.05 # Nível de significância\n",
    "p_value = anova_table['PR(>F)'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38609667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste post-hoc de Tukey HSD para comparar as médias da diferença de preço entre os pares de categorias principais. Isso nos ajudará a identificar quais categorias são significativamente diferentes umas das outras em termos do valor absoluto do desconto.\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import pandas as pd\n",
    "\n",
    "# Realizar o teste de Tukey HSD\n",
    "tukey_result = pairwise_tukeyhsd(endog=unificada_df['diferenca_preco'],\n",
    "                                  groups=unificada_df['categoria_principal'],\n",
    "                                  alpha=0.05)\n",
    "\n",
    "print(\"Resultado do Teste de Tukey HSD:\")\n",
    "\n",
    "# Converter resultado em DataFrame\n",
    "tukey_df = pd.DataFrame(tukey_result.summary().data[1:], columns=tukey_result.summary().data[0])\n",
    "\n",
    "# Converter colunas para tipos apropriados\n",
    "tukey_df[\"meandiff\"] = tukey_df[\"meandiff\"].astype(float)\n",
    "tukey_df[\"lower\"] = tukey_df[\"lower\"].astype(float)\n",
    "tukey_df[\"upper\"] = tukey_df[\"upper\"].astype(float)\n",
    "tukey_df[\"p-adj\"] = tukey_df[\"p-adj\"].astype(float)\n",
    "tukey_df[\"reject\"] = tukey_df[\"reject\"].astype(bool)\n",
    "\n",
    "# Exibir apenas as 5 primeiras linhas para não poluir o notebook\n",
    "display(tukey_df.head(5))\n",
    "\n",
    "print(\"\\nNote: Apenas as 5 primeiras combinações estão sendo exibidas para facilitar a visualização no notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf1aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular a média da diferenca_preco para cada categoria principal\n",
    "mean_diferenca_preco_por_categoria = unificada_df.groupby('categoria_principal')['diferenca_preco'].mean().sort_values(ascending=False)\n",
    "\n",
    "# Criar o gráfico de barras\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=mean_diferenca_preco_por_categoria.index, y=mean_diferenca_preco_por_categoria.values, palette='viridis')\n",
    "plt.title('Média da Diferença de Preço por Categoria Principal')\n",
    "plt.xlabel('Categoria Principal')\n",
    "plt.ylabel('Média da Diferença de Preço (R$)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe73621",
   "metadata": {},
   "source": [
    "#### Cálculo Risco Relativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd3f315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Criar a variável binária \"alta_avaliacao\" (rating >= 4.0)\n",
    "unificada_df['alta_avaliacao'] = (unificada_df['rating'] >= 4.0).astype(int)\n",
    "\n",
    "# 2. Filtrar o DataFrame para incluir apenas as categorias \"Electronics\" e \"Home&Kitchen\"\n",
    "grupos_comparacao_df = unificada_df[unificada_df['categoria_principal'].isin(['Electronics', 'Home&Kitchen'])].copy()\n",
    "\n",
    "# 3. Criar a tabela de contingência 2x2\n",
    "# Certifique-se de que a coluna 'categoria_principal' existe e não tem valores nulos nos dados filtrados\n",
    "if 'categoria_principal' in grupos_comparacao_df.columns and not grupos_comparacao_df['categoria_principal'].isnull().any():\n",
    "    tabela_contingencia = pd.crosstab(grupos_comparacao_df['categoria_principal'], grupos_comparacao_df['alta_avaliacao'])\n",
    "    print(\"Tabela de Contingência:\")\n",
    "    display(tabela_contingencia)\n",
    "\n",
    "    # Renomear as colunas para maior clareza (opcional)\n",
    "    tabela_contingencia.columns = ['Baixa Avaliação', 'Alta Avaliação']\n",
    "    tabela_contingencia.index.name = 'Categoria Principal'\n",
    "    print(\"\\nTabela de Contingência (com nomes claros):\")\n",
    "    display(tabela_contingencia)\n",
    "\n",
    "    # 4. Calcular o Risco Relativo\n",
    "    # Extrair os valores da tabela de contingência para o cálculo do RR\n",
    "    # Assumindo que 'Electronics' é o grupo exposto e 'Home&Kitchen' o não exposto\n",
    "    # E que 'Alta Avaliação' é a coluna 1 (índice 1)\n",
    "    if 'Electronics' in tabela_contingencia.index and 'Home&Kitchen' in tabela_contingencia.index:\n",
    "        a = tabela_contingencia.loc['Electronics', 'Alta Avaliação']    # Eletrônicos com alta avaliação\n",
    "        b = tabela_contingencia.loc['Electronics', 'Baixa Avaliação']   # Eletrônicos sem alta avaliação\n",
    "        c = tabela_contingencia.loc['Home&Kitchen', 'Alta Avaliação']   # Home&Kitchen com alta avaliação\n",
    "        d = tabela_contingencia.loc['Home&Kitchen', 'Baixa Avaliação']  # Home&Kitchen sem alta avaliação\n",
    "\n",
    "        # Evitar divisão por zero\n",
    "        prob_electronics = a / (a + b) if (a + b) > 0 else 0\n",
    "        prob_homekitchen = c / (c + d) if (c + d) > 0 else 0\n",
    "\n",
    "        if prob_homekitchen > 0:\n",
    "            risco_relativo = prob_electronics / prob_homekitchen\n",
    "            print(f\"\\nProbabilidade de Alta Avaliação em Electronics: {prob_electronics:.4f}\")\n",
    "            print(f\"Probabilidade de Alta Avaliação em Home&Kitchen: {prob_homekitchen:.4f}\")\n",
    "            print(f\"Risco Relativo (Electronics vs. Home&Kitchen para Alta Avaliação): {risco_relativo:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a9b436",
   "metadata": {},
   "source": [
    "#### Teste Qui-quadrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85acedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando o teste Qui-quadrado para vizualizar a diferença significativa entre os grupos em termos de risco\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Usar a tabela de contingência gerada anteriormente (tabela_contingencia)\n",
    "# chi2_contingency retorna: estatística qui-quadrado, p-valor, graus de liberdade, frequências esperadas\n",
    "chi2_stat, p_value_chi2, dof, expected_freq = chi2_contingency(tabela_contingencia)\n",
    "\n",
    "print(\"Resultado do Teste Qui-quadrado:\")\n",
    "print(f\"Estatística Qui-quadrado: {chi2_stat:.4f}\")\n",
    "print(f\"P-valor: {p_value_chi2:.4f}\")\n",
    "print(f\"Graus de Liberdade: {dof}\")\n",
    "print(\"\\nFrequências Esperadas:\")\n",
    "display(pd.DataFrame(expected_freq, columns=tabela_contingencia.columns, index=tabela_contingencia.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed68885d",
   "metadata": {},
   "source": [
    "#### Análise do Risco Relativo entre Demais Categorias de Produto (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362b9ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular e exibir o Risco Relativo para um par de categorias\n",
    "def calculate_and_display_rr(df, category1, category2, outcome_col, group_col, outcome_event=1):\n",
    "    \"\"\"\n",
    "    Calcula e exibe o Risco Relativo entre dois grupos para um evento binário.\n",
    "\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Calculando Risco Relativo: {category1} vs {category2} para {outcome_col} = {outcome_event} ---\")\n",
    "\n",
    "    # Filtrar para as duas categorias de interesse\n",
    "    comparison_df = df[df[group_col].isin([category1, category2])].copy()\n",
    "\n",
    "    # Criar tabela de contingência\n",
    "    contingency_table = pd.crosstab(comparison_df[group_col], comparison_df[outcome_col])\n",
    "\n",
    "    # Verificar se as colunas de resultado existem na tabela\n",
    "    if outcome_event not in contingency_table.columns or (1 - outcome_event) not in contingency_table.columns:\n",
    "        print(f\"Erro: Colunas de resultado binário ({outcome_event} ou {1-outcome_event}) não encontradas na tabela de contingência.\")\n",
    "        display(contingency_table)\n",
    "        return\n",
    "\n",
    "    # Extrair valores para cálculo do RR\n",
    "    # Garantir que as categorias existam na tabela\n",
    "    if category1 in contingency_table.index and category2 in contingency_table.index:\n",
    "        a = contingency_table.loc[category1, outcome_event]      # Grupo 1 com evento\n",
    "        b = contingency_table.loc[category1, 1 - outcome_event]  # Grupo 1 sem evento\n",
    "        c = contingency_table.loc[category2, outcome_event]      # Grupo 2 com evento\n",
    "        d = contingency_table.loc[category2, 1 - outcome_event]  # Grupo 2 sem evento\n",
    "\n",
    "        # Evitar divisão por zero no cálculo das probabilidades e RR\n",
    "        prob_cat1 = a / (a + b) if (a + b) > 0 else 0\n",
    "        prob_cat2 = c / (c + d) if (c + d) > 0 else 0\n",
    "\n",
    "        if prob_cat2 > 0:\n",
    "            risco_relativo = prob_cat1 / prob_cat2\n",
    "            print(f\"Probabilidade do Evento em {category1}: {prob_cat1:.4f}\")\n",
    "            print(f\"Probabilidade do Evento em {category2}: {prob_cat2:.4f}\")\n",
    "            print(f\"Risco Relativo ({category1} vs {category2}): {risco_relativo:.4f}\")\n",
    "\n",
    "# Certificar-se de que a variável binária 'alta_avaliacao' existe\n",
    "if 'alta_avaliacao' not in unificada_df.columns:\n",
    "     unificada_df['alta_avaliacao'] = (unificada_df['rating'] >= 4.0).astype(int)\n",
    "\n",
    "\n",
    "# Calcular e exibir RR para os pares sugeridos\n",
    "calculate_and_display_rr(unificada_df, 'Electronics', 'Computers&Accessories', 'alta_avaliacao', 'categoria_principal', 1)\n",
    "calculate_and_display_rr(unificada_df, 'Home&Kitchen', 'Computers&Accessories', 'alta_avaliacao', 'categoria_principal', 1)\n",
    "calculate_and_display_rr(unificada_df, 'Electronics', 'OfficeProducts', 'alta_avaliacao', 'categoria_principal', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1970164f",
   "metadata": {},
   "source": [
    "#### Validação com Teste Qui-quadrado (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "import pandas as pd\n",
    "\n",
    "# Função para realizar e exibir o Teste Qui-quadrado para um par de categorias\n",
    "def perform_and_display_chi2(df, category1, category2, outcome_col, group_col, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Realiza e exibe o Teste Qui-quadrado para a associação entre dois grupos e um evento binário.\n",
    "\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Teste Qui-quadrado: {category1} vs {category2} para {outcome_col} ---\")\n",
    "\n",
    "    # Filtrar para as duas categorias de interesse\n",
    "    comparison_df = df[df[group_col].isin([category1, category2])].copy()\n",
    "\n",
    "    # Criar tabela de contingência\n",
    "    # Certifique-se de que a coluna outcome_col é binária (0 e 1) e que os grupos existem\n",
    "    if outcome_col not in comparison_df.columns or group_col not in comparison_df.columns:\n",
    "         print(f\"Erro: Colunas '{outcome_col}' ou '{group_col}' não encontradas no DataFrame.\")\n",
    "         return\n",
    "\n",
    "    # Garantir que ambos os valores (0 e 1) estejam presentes na coluna outcome_col no filtered dataframe\n",
    "    # Isso evita erros com chi2_contingency em tabelas 2x1 ou 1x2\n",
    "    if comparison_df[outcome_col].nunique() < 2:\n",
    "        print(f\"Erro: Coluna '{outcome_col}' no subset para '{category1}' vs '{category2}' não é binária (apenas um valor encontrado).\")\n",
    "        return\n",
    "\n",
    "    # Criar tabela de contingência\n",
    "    contingency_table = pd.crosstab(comparison_df[group_col], comparison_df[outcome_col])\n",
    "\n",
    "    # Adicionar colunas ausentes (0 ou 1) com zeros se necessário, para garantir formato 2x2\n",
    "    for col_val in [0, 1]:\n",
    "        if col_val not in contingency_table.columns:\n",
    "            contingency_table[col_val] = 0\n",
    "    # Reordenar colunas para garantir consistência (0, 1)\n",
    "    contingency_table = contingency_table[[0, 1]]\n",
    "\n",
    "\n",
    "    # Realizar o teste Qui-quadrado\n",
    "    try:\n",
    "        chi2_stat, p_value, dof, expected_freq = chi2_contingency(contingency_table)\n",
    "\n",
    "        print(f\"Estatística Qui-quadrado: {chi2_stat:.4f}\")\n",
    "        print(f\"P-valor: {p_value:.4f}\")\n",
    "        print(f\"Graus de Liberdade: {dof}\")\n",
    "        print(\"\\nFrequências Observadas:\")\n",
    "        display(contingency_table)\n",
    "        print(\"\\nFrequências Esperadas:\")\n",
    "        display(pd.DataFrame(expected_freq, columns=contingency_table.columns, index=contingency_table.index))\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Erro ao realizar o teste Qui-quadrado: {e}\")\n",
    "        print(\"Verifique se a tabela de contingência tem o formato correto (pelo menos 2x2) e se há variação nos dados.\")\n",
    "\n",
    "\n",
    "# Certificar-se de que a variável binária 'alta_avaliacao' existe\n",
    "if 'alta_avaliacao' not in unificada_df.columns:\n",
    "     unificada_df['alta_avaliacao'] = (unificada_df['rating'] >= 4.0).astype(int)\n",
    "\n",
    "# Realizar testes Qui-quadrado para os pares sugeridos\n",
    "perform_and_display_chi2(unificada_df, 'Electronics', 'Computers&Accessories', 'alta_avaliacao', 'categoria_principal')\n",
    "perform_and_display_chi2(unificada_df, 'Home&Kitchen', 'Computers&Accessories', 'alta_avaliacao', 'categoria_principal')\n",
    "perform_and_display_chi2(unificada_df, 'Electronics', 'OfficeProducts', 'alta_avaliacao', 'categoria_principal')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
